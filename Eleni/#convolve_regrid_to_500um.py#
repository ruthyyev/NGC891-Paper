#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
"""This is a code to a) regrid an image from one pixel size to the pixel size of 
another, target image, b) convolve the regridded image to a specified, new beam 
size determined  by the beam sizes of the #regridded image and the target image 
and c) perfom a division between the regridded image and the target image. The 
aim of this division is to obtain ratio intensity maps in an attempt to observe 
any dust in the region of interest. The fits files used here are Hi-GAL files. 
The Hi-GAL data was obtained in parallel scan mode. (Traficante et al, 2011, 
"Data reduction pipeline for the Hi-GAL survey").
In the convolution part of the code, the argument in the Gaussian2DKernel 
(see astropy documentation, 
http://docs.astropy.org/en/stable/api/astropy.convolution.Gaussian2DKernel.html),  
is the standard #deviation in pixels at FWHM. To get this value, given the 
beam width, the approach would be to find the standard deviation (sigma) 
in arcseconds and then, for each wavelength band, divide that value with 
the pixel size to get sigma in terms of pixels instead of arcseconds."""
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------

"""For this code to work, I need to import the following packages:"""

import astropy
import os
import aplpy
from astropy.io import fits
import numpy
import montage_wrapper
from montage_wrapper import mHdr,mProject
from astropy.convolution import convolve, Gaussian2DKernel
import numpy as np
import math
from math import sqrt, log #math.log(x[, base] With one argument, return the natural logarithm of x (to base e).  https://docs.python.org/2/library/math.html
from numpy import array
#import montage_wrapper
#from montage_wrapper import mProject, mHdr

#------------------------------------------------------------------------------
                    """BASIC REQUIREMENTS"""
#------------------------------------------------------------------------------                    


os.chdir('/Users/c1541417/Documents/891Paper/Maps')
arcsec = 3600   #Number of arcseconds in a degree
ngc891_coord = '35.639, 42.349'    
print 'ngc891_coord = ' + ngc891_coord           
width = 0.5     #Size of the grid in degrees.

#------------------------------------------------------------------------------
                    """READ IN FITS FILES"""
#------------------------------------------------------------------------------

"""Read in the headers from the HIGAL fits files to be used here and extract the 
CDELT values in order to calculate the pixel sizes in arcseconds."""



#header_1mm = fits.getheader('ngc891_nika2_1mm.fits')
#header_2mm = fits.getheader('ngc891_nika2_2mm.fits')
header_70 = fits.getheader('ngc891_pacs_70.fits')
header_100 = fits.getheader('ngc891_pacs_100.fits')
header_160 = fits.getheader('ngc891_pacs_160.fits')
header_250 = fits.getheader('ngc891_spire_250.fits')
header_350 = fits.getheader('ngc891_spire_350.fits')
#The CDELT2 value is used, instead of the CDELT1, in order to avoid having to deal with the (-) sign.



#pix_size_1mm = header_1mm['CDELT2']*arcsec
#pix_size_2mm = header_2mm['CDELT2']*arcsec
pix_size_70  = header_70['CDELT2']*arcsec
pix_size_100 = header_100['CDELT2']*arcsec
pix_size_160 = header_160['CDELT2']*arcsec
pix_size_250 = header_250['CDELT2']*arcsec
pix_size_350 = header_350['CDELT2']*arcsec


#print pix_size_1mm
#print pix_size_2mm
print pix_size_70
print pix_size_100
print pix_size_160
print pix_size_250
print pix_size_350

pix_size = np.array([pix_size_70, pix_size_100, pix_size_160, pix_size_250, pix_size_350])


#------------------------------------------------------------------------------
                """PIXEL SIZE RATIOS"""
#------------------------------------------------------------------------------                

"""Here follow the area ratios between the different pixel areas. These will be 
used later in order to correct for the effect the regridding has on surface 
brightness."""

pix_ratio_350_by_70 = (pix_size[4]/pix_size[0])**2
pix_ratio_350_by_100 = (pix_size[4]/pix_size[1])**2
pix_ratio_350_by_160 = (pix_size[4]/pix_size[2])**2
pix_ratio_350_by_250 = (pix_size[4]/pix_size[3])**2


print 'pix_ratio_350_by_70 = ' + str(pix_ratio_350_by_70)
print 'pix_ratio_350_by_100 = ' + str(pix_ratio_350_by_100)
print 'pix_ratio_350_by_160 = ' + str(pix_ratio_350_by_160)
print 'pix_ratio_350_by_250 = ' + str(pix_ratio_350_by_250)


#------------------------------------------------------------------------------
                """DEFINE THE POINT SPREAD FUNCTIONS"""
#------------------------------------------------------------------------------                

"""
av_PSF_70 =(5.75+9)/2

av_PSF_70_pix =av_PSF_70/pix_size[0]                                     #Units are pixels. The average PSF was evaluated using the numbers from the PACS observers manual, Table 3.1 (http://herschel.esac.esa.int/Docs/PACS/pdf/pacs_om.pdf), using the values (5.75*9.00)

av_PSF_160 = (11.31+13.32)/2

av_PSF_160_pix =av_PSF_160/pix_size[1]                                   #Units are pixels. The average beam width was evaluated using the numbers from the PACS observers manual, Table 3.1 (http://herschel.esac.esa.int/Docs/PACS/pdf/pacs_om.pdf), using the values for the parallel mode which were (11.31 x 13.32)

av_beam_250 = 18.1/pix_size[2]                                    #Units in pixels. Value taken from http://www.aanda.org/articles/aa/pdf/2010/10/aa14519-10.pdf                                    
av_beam_350 = 25.2/pix_size[3]                                    #Units in pixels. Value taken from http://www.aanda.org/articles/aa/pdf/2010/10/aa14519-10.pdf
av_beam_500 = 36.6/pix_size[4]                                    #Units in pixels. Value taken from http://www.aanda.org/articles/aa/pdf/2010/10/aa14519-10.pdf

print 'av_PSF_70_pix = ' + str(av_PSF_70_pix)
print 'av_PSF_160_pix = ' + str(av_PSF_160_pix)
print 'av_beam_250 = ' + str(av_beam_250)
print 'av_beam_350 = ' + str(av_beam_350)
print 'av_beam_500 = ' + str(av_beam_500)





beam_70_to_500 = sqrt((av_beam_500**2)-(av_PSF_70_pix**2))         #This is the amount one needs to convolve by the 70um image in order to achieve the beam size of the 160um image.
beam_160_to_500 = sqrt((av_beam_500**2)-(av_PSF_160_pix**2))            #This is the amount one needs to convolve by the 70um image in order to achieve the beam size of the 250um image.
beam_250_to_500 = sqrt((av_beam_500**2)-(av_beam_250**2))            #This is the amount one needs to convolve by the 70um image in order to achieve the beam size of the 350um image.
beam_350_to_500 = sqrt((av_beam_500**2)-(av_beam_350**2))            #This is the amount one needs to convolve by the 70um image in order to achieve the beam size of the 500um image.


print 'beam_70_to_500 = '+ str(beam_70_to_500)                               #These four lines of code print the values of the beam change in arcseconds, i.e. how much should be added to the 9.01arcsecs beam to convolve it to the                                                  13.645arcsec beam. Same for the other three.
print 'beam_160_to_500 = ' + str(beam_160_to_500)
print 'beam_250_to_500  = ' + str(beam_250_to_500 )
print 'beam_350_to_500 = ' + str(beam_350_to_500)



const=2*sqrt(2*log(2))    
print 'const = ',float(const)                                # The equation for sigma, the standard deviation in arcseconds, given the beam at FWHM is : sigma = FWHM/2*sqrt(2*ln2). In this step, I am naming the denominator const, to simplify the code.

#Here, I am trying to express sigma in terms of pixel size than arcseconds by dividing the value of sigma ("), by pixel size to get sigma in pixels. 

sigma_70_to_500 = beam_70_to_500/const      
sigma_160_to_500 = beam_160_to_500/const
sigma_250_to_500 = beam_250_to_500/const
sigma_350_to_500 = beam_350_to_500/const


print 'sigma_70_to_500 = ' + str(sigma_70_to_500)
print 'sigma_160_to_500 = ' + str(sigma_160_to_500)
print 'sigma_250_to_500 = ' + str(sigma_250_to_500)
print 'sigma_350_to_500 = ' + str(sigma_350_to_500)



#Here follow the conversion factors for the 70um,160um,250um,350um and 500um from MJy/sr to Jy/pixel. 
# It has been calculated as follows: 1 radian = 180/pi degrees
#1 steradian = (180/pi) square degrees
#1 deg = 3600arcsecs hence 180 deg = 180*3600 arcsecs = 648000 arrcsecs
#So 1 steradian = (648000^2/3.2^2	) square arcsecs = 41006249999.99999 square arcsecs or 1 square arcsec = 2.4386526444139618e-11 steradian
#So Mjy/sr = 10^6Jy/sr * 1sr/0.4253*10^11 square arcsec = 10^6Jy/41006249999.99999 square arcsec = 2.4386526444139618*10^(-5) Jy/square arcsec

#For the 70um image. 

#1 pixel = 3.2^2 square arcsec => 1 pixel = 10.240000000000002 square arcsec => 1 square arcsec = 0.09765625 pixel
#So, 2.4386526444139618*10^(-5)Jy/square arcsec = 2.4386526444139618*10^(-5) Jy/square arcsec * 1square arcsec/0.09765625 pixel = 24.97180307879897*10^(-5) Jy/pixel
#Concluding that 1 Mjy/sr = 0.0002497180307879897 Jy/pixel

#For 160um image, pixel_size = 4.5''

#1 pixel = 4.5^2 square arcsec => 1 pixel = 20.25 square arcsecs => 1 suqare arcsec = 0.04938271604938271 pixel
#So 2.4386526444139618*10^(-5)Jy/square arcsec = 2.4386526444139618*10^(-5) Jy/square arcsec 1 square arcsec/0.04938271604938271 pixel = 0.0004938271604938273 Jy/pixel

#For the 250um image, pixel_size = 6''

#1pixel = 6^2 square arcsecs =>1 pixel = 36 square arcsecs => 1 square arcsec = 0.028 pixel
#2.4386526444139618*10^(-5)Jy/square arcsec = 2.4386526444139618*10^(-5) Jy/square arcsec 1 square arcsec/0.028 pixel = 0.0008709473730049863 Jy/pixel

#For the 350 image, pixel_size = 7.8''

#1 pixel = 7.8^2 square arcsecs => 1 pixel = 60.839999999999996 square arcsecs => 1 square arcsec = 0.01643655489809336 pixel
#2.4386526444139618*10^(-5)Jy/square arcsec = 2.4386526444139618*10^(-5) Jy/square arcsec 1 square arcsec/0.01643655489809336 pixel = 0.0014836762688614543 Jy/pixel

#For the 500um image, pixel_size = 11.5''

#1 pixel = 11.5^2 square arcsecs => 1 pixel = 132.25 square arcsecs => 1 square arcsecs = 0.007561436672967864 pixel
#2.4386526444139618*10^(-5)Jy/square arcsec = 2.4386526444139618*10^(-5) Jy/square arcsec 1 square arcsec/0.007561436672967864 pixel = 0.0032251181222374644 Jy/pixel


factor_70 = 0.0002497180307879897
factor_160 = 0.0004938271604938273
factor_250 = 0.0008709473730049863
factor_350 = 0.0014836762688614543
factor_500 = 0.0032251181222374644


#This section of the code creates a header with central coordinates those of the remnant, grid_size big enough to include the remnant and pixel size which depends upon which wavelength is chosen each time. Five headers are created, each for each wavelength. 

target_header_70 = mHdr(w44_coord, width, 'target_70.txt', pix_size=pix_size[0])
target_header_160 = mHdr(w44_coord, width, 'target_160.txt', pix_size=pix_size[1])            
target_header_250 = mHdr(w44_coord, width, 'target_250.txt', pix_size=pix_size[2])
target_header_350 = mHdr(w44_coord, width, 'target_350.txt', pix_size=pix_size[3])
target_header_500 = mHdr(w44_coord, width, 'target_500.txt', pix_size=pix_size[4])


#Here, the Gaussian2DKernel is defined (imported from astropy.convolution) is used. The parameter used is the standard deviation, sigma, in pixels for each of the different wavelengths. 

gauss_70_to_500 = Gaussian2DKernel(sigma_70_to_500)    
gauss_160_to_500 = Gaussian2DKernel(sigma_160_to_500)
gauss_250_to_500 = Gaussian2DKernel(sigma_250_to_500)
gauss_350_to_500 = Gaussian2DKernel(sigma_350_to_500)


#STEP1, convert and regrid the original HIGAL images

#70um

#Get the numpy data for the original HIGAL image. I will convert this to Jy/pixel and then the conversion should be carried over to the rest of the processes.

data_70 = fits.getdata('HIGAL0350p013_070_RM.fits')

print(data_70)

#Get the header to use in order to save the corrected file in fits format.

header_70 = fits.getheader('HIGAL0350p013_070_RM.fits')
 
#correct the data by multiplying with the conversion factor for the 70um

data_70_corrected = (data_70)*factor_70

print(data_70_corrected)

fits.writeto('HIGAL0350p013_070_RM_corrected.fits', data_70_corrected, header_70)

#CONVOLVE FIRST

convolved_image_70_to_500_new = convolve(data_70_corrected, gauss_70_to_500)


fits.writeto('70_convolved_to_500.fits', convolved_image_70_to_500_new, header_70)

#REGRIDDING

regridded_070 = mProject('HIGAL0350p013_070_RM_corrected.fits', '70_regridded.fits','target_70.txt')

regridded_70_to_500 = mProject('70_convolved_to_500.fits', '70_regridded_to_500.fits', 'target_500.txt')

data_regridded_70_to_500 = fits.getdata('70_regridded_to_500.fits')

header_regridded_70_to_500 = fits.getheader('70_regridded_to_500.fits')

data_regridded_70_to_500_scaled = data_regridded_70_to_500*pix_ratio_500_by_70

fits.writeto('70_regridded_to_500.fits', data_regridded_70_to_500_scaled, header_regridded_70_to_500, clobber=True)



   
#160um

data_160 = fits.getdata('HIGAL0350p013_160_RM.fits')

print data_160

header_160 = fits.getheader('HIGAL0350p013_160_RM.fits')

#correct the data by multiplying with the conversion factor for the 160um

data_160_corrected = (data_160)*factor_160

print(data_160_corrected)

fits.writeto('HIGAL0350p013_160_RM_corrected.fits', data_160_corrected, header_160)

regridded_160 = mProject('HIGAL0350p013_160_RM_corrected.fits', '160_regridded.fits','target_160.txt')



#Convolve and regrid 160um to 500um

#convolved_image_160_to_500_new = convolve(data_160_corrected, gauss_160_to_500)

#fits.writeto('160_convolved_to_500.fits', convolved_image_160_to_500_new, header_160)


#regridded_160_to_500 = mProject('160_convolved_to_500.fits', '160_regridded_to_500.fits', 'target_500.txt')

#data_regridded_160_to_500 = fits.getdata('160_regridded_to_500.fits')

#header_regridded_160_to_500 = fits.getheader('160_regridded_to_500.fits')

#data_regridded_160_to_500_scaled = data_regridded_160_to_500*pix_ratio_500_by_160

#fits.writeto('160_regridded_to_500.fits', data_regridded_160_to_500_scaled, header_regridded_160_to_500, clobber=True)





#250um

data_250 = fits.getdata('HIGAL0353n013_250_RM.fits')

print(data_250)

#Get the header to use in order to save the corrected file in fits format.

header_250 = fits.getheader('HIGAL0353n013_250_RM.fits')
 
#correct the data by multiplying with the conversion factor for the 70um

data_250_corrected = (data_250)*factor_250

print(data_250_corrected)

fits.writeto('HIGAL0353n013_250_RM_corrected.fits', data_250_corrected, header_250)

regridded_250 = mProject('HIGAL0353n013_250_RM_corrected.fits', '250_regridded.fits','target_250.txt')


#Convolve and regrid the 250um to the 500um

convolved_image_250_to_500_new = convolve(data_250_corrected, gauss_250_to_500)

fits.writeto('250_convolved_to_500.fits', convolved_image_250_to_500_new, header_250)


regridded_250_to_500 = mProject('250_convolved_to_500.fits', '250_regridded_to_500.fits', 'target_500.txt')

data_regridded_250_to_500 = fits.getdata('250_regridded_to_500.fits')

header_regridded_250_to_500 = fits.getheader('250_regridded_to_500.fits')

data_regridded_250_to_500_scaled = data_regridded_250_to_500*pix_ratio_500_by_250

fits.writeto('250_regridded_to_500.fits', data_regridded_250_to_500_scaled, header_regridded_250_to_500, clobber=True)



#350um

#data_350 = fits.getdata('HIGAL0353n013_350_RM.fits')

#print(data_350)

#Get the header to use in order to save the corrected file in fits format.

#header_350 = fits.getheader('HIGAL0353n013_350_RM.fits')
 
#correct the data by multiplying with the conversion factor for the 70um

#data_350_corrected = (data_350)*factor_350

#print(data_350_corrected)

#fits.writeto('HIGAL0353n013_350_RM_corrected.fits', data_350_corrected, header_350)


#regridded_350 = mProject('HIGAL0353n013_350_RM_corrected.fits', '350_regridded.fits','target_350.txt')



#convolved_image_350_to_500_new = convolve(data_350_corrected, gauss_350_to_500)

#fits.writeto('350_convolved_to_500.fits', convolved_image_350_to_500_new, header_350)


#regridded_350_to_500 = mProject('350_convolved_to_500.fits', '350_regridded_to_500.fits', 'target_500.txt')

#data_regridded_350_to_500 = fits.getdata('350_regridded_to_500.fits')

#header_regridded_350_to_500 = fits.getheader('350_regridded_to_500.fits')

#data_regridded_350_to_500_scaled = data_regridded_350_to_500*pix_ratio_500_by_350

#fits.writeto('350_regridded_to_500.fits', data_regridded_350_to_500_scaled, header_regridded_350_to_500, clobber=True)

#500um

data_500 = fits.getdata('HIGAL0353n013_500_RM.fits')

print(data_500)

#Get the header to use in order to save the corrected file in fits format.

header_500 = fits.getheader('HIGAL0353n013_500_RM.fits')
 
#correct the data by multiplying with the conversion factor for the 70um

data_500_corrected = (data_500)*factor_500

print(data_500_corrected)

fits.writeto('HIGAL0353n013_500_RM_corrected.fits', data_500_corrected, header_500)

#REGRIDDING

regridded_500 = mProject('HIGAL0353n013_500_RM_corrected.fits', '500_regridded.fits','target_500.txt')


#data_70_regridded = fits.getdata('70_regridded.fits')
#data_160_regridded = fits.getdata('160_regridded.fits')
data_250_regridded = fits.getdata('250_regridded.fits')
#data_350_regridded = fits.getdata('350_regridded.fits')
data_500_regridded = fits.getdata('500_regridded.fits')


#data_70_regridded_to_500 = fits.getdata('70_regridded_to_500.fits')
#data_160_regridded_to_500 = fits.getdata('160_regridded_to_500.fits')
data_250_regridded_to_500 = fits.getdata('250_regridded_to_500.fits')
#data_350_regridded_to_500 = fits.getdata('350_regridded_to_500.fits')


#STEP 3, getting the ratio images. 

#divided_data_70_over_500 = numpy.divide(data_70_regridded_to_500,data_500_regridded)
#divided_data_160_over_500 = numpy.divide(data_160_regridded_to_500,data_500_regridded)
divided_data_250_over_500 = numpy.divide(data_250_regridded_to_500,data_500_regridded)
#divided_data_350_over_500 = numpy.divide(data_350_regridded_to_500,data_500_regridded)


#fits.writeto('70_by_500.fits', divided_data_70_over_500, header_500)
#fits.writeto('160_by_500.fits', divided_data_160_over_500, header_500)
fits.writeto('250_by_500.fits', divided_data_250_over_500, header_500)
#fits.writeto('350_by_500.fits', divided_data_350_over_500, header_500)


"""